{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Image to Text Supervised Fine-Tuning with Align-Anything\n",
    "\n",
    "This tutorial introduces how to perform supervised fine-tuning (SFT) on multimodal models using the Align-Anything framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "- Align-Anything installed.\n",
    "- A text-image-to-text dataset, in this tutorialm, we use the [PKU-Alignment/Align-Anything-TI2T-Instruction-100K](https://huggingface.co/datasets/PKU-Alignment/Align-Anything-TI2T-Instruction-100K) dataset.\n",
    "- LLaVA-1.5-7b model, you can download it from [here](https://huggingface.co/llava-hf/llava-1.5-7b-hf).\n",
    "- A GPU with at least 70GB of memory.\n",
    "> A lower memory GPU is also possible. We will provide a script using smaller models in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pre-trained Models\n",
    "\n",
    "First, we need to load a pre-trained model. We'll use the LLaVA-1.5-7b model, which is a multimodal model capable of understanding both text and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from align_anything.models.pretrained_model import load_pretrained_models\n",
    "from align_anything.utils.multi_process import get_current_device\n",
    "\n",
    "# Load the pre-trained model, tokenizer, and processor\n",
    "model, tokenizer, processor = load_pretrained_models(\n",
    "    \"/path/to/llava-1.5-7b-hf\",  # Replace with your model path\n",
    "    model_max_length=4096,\n",
    "    padding_side='right',\n",
    "    trust_remote_code=True,\n",
    "    modality=['image'],\n",
    ")\n",
    "\n",
    "# Move the model to the available device (GPU if available)\n",
    "model = model.to(get_current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Optimizer\n",
    "\n",
    "For fine-tuning, we'll use the AdamW optimizer, which is a popular choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Initialize the optimizer with a learning rate of 1e-5\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Configuring the Chat Template\n",
    "\n",
    "Align-Anything uses chat templates to format the input for the model. Here, we're using the *AA_TI2T* template, which is designed for align-anything text-image-to-text datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from align_anything.configs.template import ChatTemplate\n",
    "\n",
    "train_template = ChatTemplate(\n",
    "    formatter=processor,\n",
    "    template=\"AA_TI2T\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template is a dataset-specific formatter, mapping the input data to the model's input format. Here is the detail of the *AA_TI2T* template:\n",
    "\n",
    "```python\n",
    "@register_template('AA_TI2T')\n",
    "class AA_TI2T(BaseFormatter):\n",
    "    system_prompt: str = ''\n",
    "    \n",
    "    def format_supervised_sample(\n",
    "        self, raw_sample: dict[str, Any]\n",
    "    ) -> tuple[list[dict[str, Any]], dict[str, Any]]:\n",
    "        prompt = raw_sample['prompt']\n",
    "        answer = raw_sample['response']\n",
    "        image = raw_sample['image'].convert('RGBA')\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': [\n",
    "                    {'type': 'image'},\n",
    "                    {'type': 'text', 'text': prompt},\n",
    "                ],\n",
    "            },\n",
    "            {'role': 'assistant', 'content': [{'type': 'text', 'text': answer}]},\n",
    "        ], {'image': image}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset\n",
    "\n",
    "We'll use the SupervisedDataset class to load our text-image-to-text dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from align_anything.datasets.text_image_to_text import SupervisedDataset\n",
    "\n",
    "# Initialize the training dataset\n",
    "train_dataset = SupervisedDataset(\n",
    "    path=\"/path/to/Align-Anything-TI2T-Instruction-100K\",  # Replace with your dataset path\n",
    "    template=train_template,\n",
    "    tokenizer=tokenizer,\n",
    "    processor=processor,\n",
    "    split=\"train\",\n",
    "    size=1000,  # Limit to 1000 samples for this tutorial\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the DataLoader\n",
    "\n",
    "The DataLoader will handle batching, shuffling, and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "# Create a DataLoader for our training dataset\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=train_dataset.get_collator(),  # Custom collate function for our dataset\n",
    "    sampler=RandomSampler(train_dataset),     # Randomly sample data\n",
    "    batch_size=1,                             # Process one sample at a time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Now we'll fine-tune the model for a few epochs. We save the model after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "progress_bar = tqdm(range(3*len(train_dataloader)), desc=\"Training for 1/3 epochs...\")\n",
    "losses = deque(maxlen=100)\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    progress_bar.set_description(f\"Training for {epoch+1}/3 epochs...\")\n",
    "    for batch in train_dataloader:\n",
    "        batch.pop('meta_info')\n",
    "        model.train()\n",
    "        loss = model(**batch)['loss']\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_postfix(loss=np.mean(losses))\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    model.save_pretrained('./output')\n",
    "    tokenizer.save_pretrained('./output')\n",
    "    processor.save_pretrained('./output')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete code is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from align_anything.models.pretrained_model import load_pretrained_models\n",
    "from align_anything.datasets.text_image_to_text import SupervisedDataset\n",
    "from align_anything.configs.template import ChatTemplate\n",
    "from align_anything.utils.multi_process import get_current_device\n",
    "\n",
    "\n",
    "model, tokenizer, processor = load_pretrained_models(\n",
    "    \"/path/to/llava-1.5-7b-hf\",\n",
    "    model_max_length=4096,\n",
    "    padding_side='right',\n",
    "    trust_remote_code=True,\n",
    "    modality=['image'],\n",
    ")\n",
    "\n",
    "model = model.to(get_current_device())\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "train_template = ChatTemplate(\n",
    "    formatter=processor,\n",
    "    template=\"AA_TI2T\",\n",
    ")\n",
    "\n",
    "train_dataset = SupervisedDataset(\n",
    "    path=\"/path/to/Align-Anything-TI2T-Instruction-100K\",  # Replace with your dataset path\n",
    "    template=train_template,\n",
    "    tokenizer=tokenizer,\n",
    "    processor=processor,\n",
    "    split=\"train\",\n",
    "    size=1000,  # Limit to 1000 samples for this tutorial\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=train_dataset.get_collator(),\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(3*len(train_dataloader)), desc=\"Training for 1/3 epochs...\")\n",
    "losses = deque(maxlen=100)\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    progress_bar.set_description(f\"Training for {epoch+1}/3 epochs...\")\n",
    "    for batch in train_dataloader:\n",
    "        batch.pop('meta_info')\n",
    "        model.train()\n",
    "        loss = model(**batch)['loss']\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_postfix(loss=np.mean(losses))\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    model.save_pretrained('./output')\n",
    "    tokenizer.save_pretrained('./output')\n",
    "    processor.save_pretrained('./output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jy-align",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
