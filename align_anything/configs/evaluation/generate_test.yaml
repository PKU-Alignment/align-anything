infer_cfgs:
  # The deepspeed configuration
  ds_cfgs: ds_z3_config.json
  vllm_cfgs: vllm_basic.json
  
default:
  # evaluation configurations
  eval_cfgs:
    # Seed for random number generator
    seed: 0
    # judge model, options: [gpt-4]
    judge_model: gpt-4
    # The number of choices
    num_choices: 1
    # Output directory name
    output_dir: /aifs4su/yaodong/donghai/align-anything/align_anything/evaluation/meta_test_output
  # Configuration for data
  data_cfgs:
    # Task name
    task: default
    # Task directory
    task_dir: /aifs4su/yaodong/donghai/align-anything/align_anything/evaluation/datasets/gsm8k/
    # Evaluation split
    split: test

  # Model configurations
  model_cfgs:
    # Model ID
    model_id: Llama-3-8B
    # Model name or path
    model_name_or_path: /aifs4su/yaodong/models/alpaca-7b-reproduced
    # Chat template
    chat_template: PKUSafeRLHF
    # Whether to trust remote code
    trust_remote_code: True
    # The max token length
    model_max_length: 4096
    # The max token length for generation
    max_new_token: 1024
