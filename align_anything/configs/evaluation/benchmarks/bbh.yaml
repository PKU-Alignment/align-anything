infer_cfgs:
  # The deepspeed configuration
  ds_cfgs: ds_z3_config.json
  vllm_cfgs: vllm_basic.json
  
default:
  # Evaluation configurations
  eval_cfgs:
    # Output directory name
    output_dir: null
    # Num shot
    n_shot: 3
    # Use Chain of Thought
    cot: True
  # Configuration for data
  data_cfgs:
    # Task name
    task: [boolean_expressions, dyck_languages, causal_judgement, date_understanding, disambiguation_qa, formal_fallacies, geometric_shapes, hyperbaton, logical_deduction_five_objects, logical_deduction_seven_objects, logical_deduction_three_objects,  movie_recommendation, multistep_arithmetic_two, navigate, object_counting, penguins_in_a_table, reasoning_about_colored_objects, ruin_names, salient_translation_error_detection, snarks, sports_understanding, temporal_sequences, tracking_shuffled_objects_five_objects, tracking_shuffled_objects_seven_objects, tracking_shuffled_objects_three_objects, web_of_lies, word_sorting]
    # Task directory
    task_dir: lukaemon/bbh
    # Evaluation split
    split: test

  # Model configurations
  model_cfgs:
    model_id: Meta-Llama-3-8B-Instruct
    # Pretrained model name or path
    model_name_or_path: meta-llama/Meta-Llama-3-8B-Instruct
    # Chat template
    chat_template: Llama3
    # The max token length
    model_max_length: 2048

