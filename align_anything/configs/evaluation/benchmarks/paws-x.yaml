infer_cfgs:
  # The deepspeed configuration
  ds_cfgs: ds_z3_config.json
  vllm_cfgs: vllm_basic.json
  
default:
  # Evaluation configurations
  eval_cfgs:
    # batch_size: 1
    # Seed for random number generator
    seed: 0
    # Output directory name
    output_dir: null
    # Num shot
    n_shot: 5
    # Use Chain of Thought
    cot: false
    # Evaluation method
    action: generation
  # Configuration for data
  data_cfgs:
    # Task name
    task: 'en'
    # Task directory
    task_dir: google-research-datasets/paws-x
    # Evaluation split
    split: 'test'
    # Candidate labels
    candidate_labels: ['1', '0']

  # # Model configurations
  # model_cfgs:
  #   model_id: Qwen2-1.5B
  #   # Pretrained model name or path
  #   model_name_or_path: /aifs4su/yaodong/models/qwen/Qwen2-1.5B
  #   # Chat template
  #   chat_template: Qwen
  #   # Whether to trust remote code
  #   trust_remote_code: True
  #   # The max token length
  #   model_max_length: 2048
  model_cfgs:
    model_id: Meta-Llama-3-8B-Instruct
    # Pretrained model name or path
    model_name_or_path: /aifs4su/yaodong/models/Meta-Llama-3-8B-Instruct
    # Chat template
    chat_template: Llama3
    # Whether to trust remote code
    trust_remote_code: True
    # The max token length
    model_max_length: 2048