# Copyright 2024 PKU-Alignment Team. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

infer_cfgs:
  # The deepspeed configuration
  ds_cfgs: ds_z3_config.json
  vllm_cfgs: vllm_basic.json
  
default:
  # Evaluation configurations
  eval_cfgs:
    # Output directory name
    output_dir: null
    # Num shot
    n_shot: 0
    # Evaluation method
    action: generation
  # Configuration for data
  data_cfgs:
    # Task name
    task: default
    # Task directory
    task_dir: lmms-lab/MME
    # Evaluation split
    split: test

  # Model configurations
  model_cfgs:
    model_id: llava-1.5-7b-hf
    # Pretrained model name or path
    model_name_or_path: llava-hf/llava-1.5-7b-hf
    # Chat template
    chat_template: LLAVA
    # Whether to trust remote code
    trust_remote_code: True
    # The max token length
    max_length: 1024
    # The max new tokens for generation
    max_new_tokens: 512
