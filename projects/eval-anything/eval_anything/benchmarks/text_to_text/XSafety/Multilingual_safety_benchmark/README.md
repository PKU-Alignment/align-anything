ref: https://github.com/Jarviswang94/Multilingual_safety_benchmark/blob/main/README.md

<h1 align="center">Multilingual Safety Benchmark for LLMs</h1>
Paper: All Languages Matter: On the Multilingual Safety of Large Language Model.
<br>   <br>

<div align="center">
  <img src="paper/Overview.png" width="800">
</div>

<h3 align="center">RESEARCH USE ONLYâœ… NO MISUSEâŒ</h3>



## ğŸ’¡Framework
<div align="center">
  <img src="paper/framework.jpg" alt="Logo" width="1000">
</div>


We build the first multilingual safety benchmark for LLMs, XSafety, in response to the global deployment of LLMs in practice. XSafety covers 14 kinds of commonly used safety issues across 10 languages that span several language families.
We utilize XSafety to empirically study the multilingual safety for 4 widely-used LLMs, including both close-API and open-source models. Experimental results show that all LLMs produce significantly more unsafe responses for non-English queries than English ones, indicating the necessity of developing safety alignment for non-English languages


## ğŸ“ƒResults

<div align="center">
  <img src="paper/result1.jpg" alt="Logo" width="800">
</div>

<div align="center">
  <img src="paper/result2.jpg" alt="Logo" width="800">
</div>




## ğŸ‘‰ Paper and Citation
For more details, please refer to our paper <a href="http://arxiv.org/abs/2310.00905">here</a>.


Community Discussion:
- Twitter: [AIDB](), [Jiao Wenxiang]()

## Citation

If you find our paper&data interesting and useful, please feel free to give us a star and cite us through:
```bibtex
@article{wang2023all,
  title={All Languages Matter: On the Multilingual Safety of Large Language Models},
  author={Wang, Wenxuan and Tu, Zhaopeng and Chen, Chang and Yuan, Youliang and Huang, Jen-tse and Jiao, Wenxiang and Lyu, Michael R},
  journal={arXiv preprint arXiv:2310.00905},
  year={2023}
}
```
